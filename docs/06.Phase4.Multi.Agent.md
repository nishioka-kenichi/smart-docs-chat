# Phase 4: ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ã‚¬ã‚¤ãƒ‰

## ğŸ“Œ æ¦‚è¦

Phase 4ã§ã¯ã€è¤‡æ•°ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”èª¿ã—ã¦å‹•ä½œã™ã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

## ğŸ¯ Day 3-4ã®ç›®æ¨™

### Day 3: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŸ¥èƒ½åŒ–
- [ ] ã‚»ãƒ«ãƒ•ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã®å®Ÿè£…
- [ ] è¦ä»¶å®šç¾©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] Plan-and-Executeãƒ‘ã‚¿ãƒ¼ãƒ³

### Day 4: ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç³»
- [ ] Supervisorå‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- [ ] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“é€šä¿¡
- [ ] Streamlit UIçµ±åˆ

---

## ğŸ¤– ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### Supervisorå‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```mermaid
graph TB
    User[User] --> Supervisor[Supervisor Agent]
    
    Supervisor --> Researcher[Researcher Agent]
    Supervisor --> Coder[Coder Agent]
    Supervisor --> Reviewer[Reviewer Agent]
    Supervisor --> Documenter[Documenter Agent]
    
    Researcher --> SharedMemory[(Shared Memory)]
    Coder --> SharedMemory
    Reviewer --> SharedMemory
    Documenter --> SharedMemory
    
    SharedMemory --> Supervisor
    Supervisor --> User
    
    style Supervisor fill:#FFD700
    style SharedMemory fill:#87CEEB
```

---

## ğŸ”§ Day 3: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŸ¥èƒ½åŒ–

### 1. ã‚»ãƒ«ãƒ•ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```python
# phase04-multi-agent/src/self_reflection.py

from typing import Dict, List, Optional
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field

class ReflectionResult(BaseModel):
    """ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµæœ"""
    quality_score: float = Field(description="å“è³ªã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰")
    completeness: float = Field(description="å®Œå…¨æ€§ï¼ˆ0-10ï¼‰")
    clarity: float = Field(description="æ˜ç­æ€§ï¼ˆ0-10ï¼‰")
    improvements: List[str] = Field(description="æ”¹å–„ç‚¹")
    is_satisfactory: bool = Field(description="æº€è¶³ã§ãã‚‹ã‹")

class SelfReflectionAgent:
    """è‡ªå·±è©•ä¾¡ãƒ»æ”¹å–„ã‚’è¡Œã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self, max_iterations: int = 3):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        self.max_iterations = max_iterations
        
        self.reflection_prompt = PromptTemplate(
            input_variables=["task", "response", "criteria"],
            template="""
            ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã¨å¿œç­”ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
            
            ã‚¿ã‚¹ã‚¯: {task}
            
            å¿œç­”: {response}
            
            è©•ä¾¡åŸºæº–:
            {criteria}
            
            ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
            - quality_score: å…¨ä½“çš„ãªå“è³ª (0-10)
            - completeness: ã‚¿ã‚¹ã‚¯ã®å®Œå…¨æ€§ (0-10)
            - clarity: æ˜ç­æ€§ãƒ»ç†è§£ã—ã‚„ã™ã• (0-10)
            - improvements: æ”¹å–„ã™ã¹ãç‚¹ã®ãƒªã‚¹ãƒˆ
            - is_satisfactory: åˆæ ¼åŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ (true/false)
            """
        )
        
        self.improvement_prompt = PromptTemplate(
            input_variables=["task", "original_response", "feedback"],
            template="""
            ä»¥ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åŸºã«å¿œç­”ã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚
            
            ã‚¿ã‚¹ã‚¯: {task}
            
            å…ƒã®å¿œç­”: {original_response}
            
            ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {feedback}
            
            æ”¹å–„ã•ã‚ŒãŸå¿œç­”:
            """
        )
    
    def reflect(self, task: str, response: str, criteria: str = "") -> ReflectionResult:
        """å¿œç­”ã‚’è©•ä¾¡"""
        if not criteria:
            criteria = """
            - ã‚¿ã‚¹ã‚¯ã®è¦æ±‚ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹
            - æƒ…å ±ã®æ­£ç¢ºæ€§
            - è«–ç†çš„ãªæ§‹æˆ
            - å®Ÿç”¨æ€§
            """
        
        prompt = self.reflection_prompt.format(
            task=task,
            response=response,
            criteria=criteria
        )
        
        result = self.llm.invoke(prompt)
        
        # JSONãƒ‘ãƒ¼ã‚¹
        import json
        try:
            reflection_data = json.loads(result.content)
            return ReflectionResult(**reflection_data)
        except:
            # ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            return ReflectionResult(
                quality_score=5.0,
                completeness=5.0,
                clarity=5.0,
                improvements=["Could not parse reflection"],
                is_satisfactory=False
            )
    
    def improve(self, task: str, response: str, feedback: List[str]) -> str:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åŸºã«å¿œç­”ã‚’æ”¹å–„"""
        feedback_text = "\n".join([f"- {f}" for f in feedback])
        
        prompt = self.improvement_prompt.format(
            task=task,
            original_response=response,
            feedback=feedback_text
        )
        
        result = self.llm.invoke(prompt)
        return result.content
    
    def execute_with_reflection(
        self,
        task: str,
        initial_response_generator,
        criteria: str = ""
    ) -> Dict:
        """ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä»˜ãã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ"""
        iteration = 0
        current_response = initial_response_generator(task)
        history = []
        
        while iteration < self.max_iterations:
            # ç¾åœ¨ã®å¿œç­”ã‚’è©•ä¾¡
            reflection = self.reflect(task, current_response, criteria)
            
            history.append({
                "iteration": iteration,
                "response": current_response,
                "reflection": reflection.dict()
            })
            
            # æº€è¶³ã§ãã‚‹å ´åˆã¯çµ‚äº†
            if reflection.is_satisfactory:
                break
            
            # æ”¹å–„ãŒå¿…è¦ãªå ´åˆ
            if reflection.improvements:
                current_response = self.improve(
                    task,
                    current_response,
                    reflection.improvements
                )
            
            iteration += 1
        
        return {
            "final_response": current_response,
            "iterations": iteration + 1,
            "history": history,
            "final_score": history[-1]["reflection"]["quality_score"] if history else 0
        }
```

### 2. è¦ä»¶å®šç¾©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```python
# phase04-multi-agent/src/requirements_agent.py

from typing import Dict, List
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

class UserPersona(BaseModel):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒšãƒ«ã‚½ãƒŠ"""
    name: str = Field(description="ãƒšãƒ«ã‚½ãƒŠå")
    role: str = Field(description="å½¹å‰²")
    goals: List[str] = Field(description="ç›®æ¨™")
    pain_points: List[str] = Field(description="èª²é¡Œãƒ»ç—›ã¿")
    expectations: List[str] = Field(description="æœŸå¾…")

class Requirement(BaseModel):
    """è¦ä»¶"""
    category: str = Field(description="ã‚«ãƒ†ã‚´ãƒª")
    description: str = Field(description="èª¬æ˜")
    priority: str = Field(description="å„ªå…ˆåº¦")
    acceptance_criteria: List[str] = Field(description="å—å…¥åŸºæº–")

class RequirementsAgent:
    """è¦ä»¶å®šç¾©ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    
    def generate_personas(self, project_description: str) -> List[UserPersona]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆ"""
        prompt = f"""
        ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é–¢é€£ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒšãƒ«ã‚½ãƒŠã‚’3ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_description}
        
        å„ãƒšãƒ«ã‚½ãƒŠã«ã¤ã„ã¦ä»¥ä¸‹ã‚’å«ã‚ã¦JSONå½¢å¼ã§å‡ºåŠ›:
        - name: ãƒšãƒ«ã‚½ãƒŠå
        - role: å½¹å‰²ãƒ»è·ç¨®
        - goals: ç›®æ¨™ï¼ˆ3ã¤ï¼‰
        - pain_points: èª²é¡Œãƒ»ç—›ã¿ï¼ˆ3ã¤ï¼‰
        - expectations: æœŸå¾…ï¼ˆ3ã¤ï¼‰
        """
        
        response = self.llm.invoke(prompt)
        
        # JSONãƒ‘ãƒ¼ã‚¹ã—ã¦UserPersonaã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        import json
        personas_data = json.loads(response.content)
        
        return [UserPersona(**p) for p in personas_data]
    
    def interview_persona(self, persona: UserPersona, context: str) -> List[Dict[str, str]]:
        """ãƒšãƒ«ã‚½ãƒŠã«ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"""
        prompt = f"""
        ã‚ãªãŸã¯{persona.name}ã¨ã„ã†{persona.role}ã§ã™ã€‚
        ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã¤ã„ã¦ã€5ã¤ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
        
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
        
        ç›®æ¨™: {persona.goals}
        èª²é¡Œ: {persona.pain_points}
        
        è³ªå•:
        1. ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã§æœ€ã‚‚é‡è¦ãªæ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ
        2. ç¾åœ¨ã®æ¥­å‹™ã§æœ€ã‚‚æ™‚é–“ãŒã‹ã‹ã‚‹ä½œæ¥­ã¯ä½•ã§ã™ã‹ï¼Ÿ
        3. ç†æƒ³çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
        4. ã©ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¬ãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã™ã‹ï¼Ÿ
        5. ã‚·ã‚¹ãƒ†ãƒ ã«æœŸå¾…ã™ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ï¼Ÿ
        """
        
        response = self.llm.invoke(prompt)
        
        # å›ç­”ã‚’ãƒ‘ãƒ¼ã‚¹
        answers = response.content.split("\n\n")
        
        interview_results = []
        questions = [
            "æœ€ã‚‚é‡è¦ãªæ©Ÿèƒ½",
            "æ™‚é–“ãŒã‹ã‹ã‚‹ä½œæ¥­",
            "ç†æƒ³çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
            "å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ¬ãƒãƒ¼ãƒˆ",
            "æœŸå¾…ã™ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹"
        ]
        
        for q, a in zip(questions, answers):
            interview_results.append({
                "question": q,
                "answer": a.strip()
            })
        
        return interview_results
    
    def generate_requirements(
        self,
        project_description: str,
        interviews: List[Dict]
    ) -> List[Requirement]:
        """ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼çµæœã‹ã‚‰è¦ä»¶ã‚’ç”Ÿæˆ"""
        interview_summary = "\n".join([
            f"- {i['question']}: {i['answer']}"
            for i in interviews
        ])
        
        prompt = f"""
        ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã‚’5ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_description}
        
        ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼çµæœ:
        {interview_summary}
        
        å„è¦ä»¶ã«ã¤ã„ã¦JSONå½¢å¼ã§å‡ºåŠ›:
        - category: æ©Ÿèƒ½/éæ©Ÿèƒ½/ãƒ“ã‚¸ãƒã‚¹
        - description: è¦ä»¶ã®èª¬æ˜
        - priority: é«˜/ä¸­/ä½
        - acceptance_criteria: å—å…¥åŸºæº–ï¼ˆ3ã¤ï¼‰
        """
        
        response = self.llm.invoke(prompt)
        
        import json
        requirements_data = json.loads(response.content)
        
        return [Requirement(**r) for r in requirements_data]
```

### 3. Plan-and-Executeãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# phase04-multi-agent/src/plan_execute.py

from typing import List, Dict, Any
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

class TaskPlan(BaseModel):
    """ã‚¿ã‚¹ã‚¯è¨ˆç”»"""
    step_number: int = Field(description="ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·")
    description: str = Field(description="ã‚¿ã‚¹ã‚¯èª¬æ˜")
    dependencies: List[int] = Field(description="ä¾å­˜ã‚¹ãƒ†ãƒƒãƒ—")
    estimated_time: str = Field(description="æ¨å®šæ™‚é–“")
    required_tools: List[str] = Field(description="å¿…è¦ãªãƒ„ãƒ¼ãƒ«")

class PlanExecuteAgent:
    """Plan-and-Executeãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.planner = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        self.executor = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    def create_plan(self, objective: str, context: str = "") -> List[TaskPlan]:
        """ç›®æ¨™ã‹ã‚‰è¨ˆç”»ã‚’ä½œæˆ"""
        prompt = f"""
        ä»¥ä¸‹ã®ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã®è©³ç´°ãªã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®è¨ˆç”»ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ç›®æ¨™: {objective}
        
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
        
        å„ã‚¹ãƒ†ãƒƒãƒ—ã«ã¤ã„ã¦JSONå½¢å¼ã§å‡ºåŠ›:
        - step_number: ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·
        - description: ä½•ã‚’ã™ã‚‹ã‹
        - dependencies: ä¾å­˜ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·ã®ãƒªã‚¹ãƒˆ
        - estimated_time: æ¨å®šæ™‚é–“
        - required_tools: å¿…è¦ãªãƒ„ãƒ¼ãƒ«ãƒ»ãƒªã‚½ãƒ¼ã‚¹
        """
        
        response = self.planner.invoke(prompt)
        
        import json
        plan_data = json.loads(response.content)
        
        return [TaskPlan(**step) for step in plan_data]
    
    def execute_step(
        self,
        step: TaskPlan,
        previous_results: Dict[int, Any]
    ) -> Dict:
        """å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
        # ä¾å­˜çµæœã‚’åé›†
        dependencies_context = ""
        for dep in step.dependencies:
            if dep in previous_results:
                dependencies_context += f"\nã‚¹ãƒ†ãƒƒãƒ—{dep}ã®çµæœ: {previous_results[dep]}"
        
        prompt = f"""
        ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¹ã‚¯: {step.description}
        
        åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«: {step.required_tools}
        
        å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã®çµæœ:
        {dependencies_context}
        
        å®Ÿè¡Œçµæœã‚’è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        """
        
        response = self.executor.invoke(prompt)
        
        return {
            "step_number": step.step_number,
            "description": step.description,
            "result": response.content,
            "status": "completed"
        }
    
    def execute_plan(self, plan: List[TaskPlan]) -> List[Dict]:
        """è¨ˆç”»å…¨ä½“ã‚’å®Ÿè¡Œ"""
        results = {}
        execution_log = []
        
        for step in plan:
            # ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯
            can_execute = all(
                dep in results for dep in step.dependencies
            )
            
            if can_execute:
                result = self.execute_step(step, results)
                results[step.step_number] = result["result"]
                execution_log.append(result)
            else:
                execution_log.append({
                    "step_number": step.step_number,
                    "description": step.description,
                    "status": "skipped",
                    "reason": "Dependencies not met"
                })
        
        return execution_log
```

---

## ğŸ”§ Day 4: ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 

### 1. Supervisorã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```python
# phase04-multi-agent/src/supervisor.py

from typing import Dict, List, Any, Optional
from langchain_openai import ChatOpenAI
from enum import Enum
import asyncio

class AgentType(Enum):
    RESEARCHER = "researcher"
    CODER = "coder"
    REVIEWER = "reviewer"
    DOCUMENTER = "documenter"

class SupervisorAgent:
    """Supervisorã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç®¡ç†"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        self.agents = {}
        self.shared_memory = {}
    
    def register_agent(self, agent_type: AgentType, agent: Any):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç™»éŒ²"""
        self.agents[agent_type] = agent
    
    def analyze_task(self, task: str) -> List[AgentType]:
        """ã‚¿ã‚¹ã‚¯ã‚’åˆ†æã—ã¦å¿…è¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ±ºå®š"""
        prompt = f"""
        ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’åˆ†æã—ã€å¿…è¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¹ã‚¯: {task}
        
        åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:
        - researcher: æƒ…å ±åé›†ãƒ»èª¿æŸ»
        - coder: ã‚³ãƒ¼ãƒ‰ä½œæˆãƒ»å®Ÿè£…
        - reviewer: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»å“è³ªãƒã‚§ãƒƒã‚¯
        - documenter: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
        
        å¿…è¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å‡ºåŠ›:
        """
        
        response = self.llm.invoke(prompt)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
        agent_names = response.content.strip().split(",")
        agent_types = []
        
        for name in agent_names:
            name = name.strip()
            try:
                agent_type = AgentType(name)
                agent_types.append(agent_type)
            except ValueError:
                continue
        
        return agent_types
    
    def delegate_task(
        self,
        agent_type: AgentType,
        task: str,
        context: Dict = None
    ) -> Dict:
        """ã‚¿ã‚¹ã‚¯ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å§”è­²"""
        if agent_type not in self.agents:
            return {
                "error": f"Agent {agent_type.value} not found",
                "status": "failed"
            }
        
        agent = self.agents[agent_type]
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
        full_context = {
            "task": task,
            "shared_memory": self.shared_memory,
            "additional_context": context or {}
        }
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
        result = agent.execute(full_context)
        
        # çµæœã‚’å…±æœ‰ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
        self.shared_memory[agent_type.value] = result
        
        return result
    
    async def coordinate_agents(
        self,
        task: str,
        sequential: bool = False
    ) -> Dict:
        """è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èª¿æ•´"""
        # å¿…è¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆ†æ
        required_agents = self.analyze_task(task)
        
        if sequential:
            # é †æ¬¡å®Ÿè¡Œ
            results = {}
            for agent_type in required_agents:
                result = self.delegate_task(agent_type, task)
                results[agent_type.value] = result
        else:
            # ä¸¦åˆ—å®Ÿè¡Œ
            tasks = [
                asyncio.create_task(
                    asyncio.to_thread(
                        self.delegate_task,
                        agent_type,
                        task
                    )
                )
                for agent_type in required_agents
            ]
            
            agent_results = await asyncio.gather(*tasks)
            results = {
                agent_type.value: result
                for agent_type, result in zip(required_agents, agent_results)
            }
        
        # çµ±åˆçµæœã‚’ç”Ÿæˆ
        return self.synthesize_results(task, results)
    
    def synthesize_results(self, task: str, results: Dict) -> Dict:
        """è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã‚’çµ±åˆ"""
        results_summary = "\n".join([
            f"{agent}: {result.get('summary', str(result)[:200])}"
            for agent, result in results.items()
        ])
        
        prompt = f"""
        ä»¥ä¸‹ã®è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã‚’çµ±åˆã—ã¦ã€
        æœ€çµ‚çš„ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        å…ƒã®ã‚¿ã‚¹ã‚¯: {task}
        
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœ:
        {results_summary}
        
        çµ±åˆã•ã‚ŒãŸæœ€çµ‚å¿œç­”:
        """
        
        response = self.llm.invoke(prompt)
        
        return {
            "task": task,
            "agents_used": list(results.keys()),
            "individual_results": results,
            "final_answer": response.content,
            "shared_memory": self.shared_memory
        }
```

### 2. å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…

```python
# phase04-multi-agent/src/specialized_agents.py

from typing import Dict, Any
from langchain_openai import ChatOpenAI
from abc import ABC, abstractmethod

class BaseAgent(ABC):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, name: str):
        self.name = name
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    @abstractmethod
    def execute(self, context: Dict) -> Dict:
        pass

class ResearcherAgent(BaseAgent):
    """èª¿æŸ»ãƒ»æƒ…å ±åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        super().__init__("Researcher")
    
    def execute(self, context: Dict) -> Dict:
        task = context.get("task", "")
        
        prompt = f"""
        ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦èª¿æŸ»ã—ã€è©³ç´°ãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¹ã‚¯: {task}
        
        èª¿æŸ»å†…å®¹:
        1. èƒŒæ™¯æƒ…å ±
        2. é–¢é€£æŠ€è¡“
        3. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
        4. æ³¨æ„ç‚¹
        5. å‚è€ƒè³‡æ–™
        """
        
        response = self.llm.invoke(prompt)
        
        return {
            "agent": self.name,
            "task": task,
            "research": response.content,
            "summary": response.content[:200] + "...",
            "status": "completed"
        }

class CoderAgent(BaseAgent):
    """ã‚³ãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        super().__init__("Coder")
    
    def execute(self, context: Dict) -> Dict:
        task = context.get("task", "")
        shared_memory = context.get("shared_memory", {})
        
        # ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã®çµæœãŒã‚ã‚Œã°å‚ç…§
        research = shared_memory.get("researcher", {}).get("research", "")
        
        prompt = f"""
        ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¹ã‚¯: {task}
        
        å‚è€ƒæƒ…å ±:
        {research[:500] if research else "ãªã—"}
        
        ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ãã ã•ã„:
        - ã‚¯ãƒªãƒ¼ãƒ³ã§èª­ã¿ã‚„ã™ã„
        - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å«ã‚€
        - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä»˜ã
        """
        
        response = self.llm.invoke(prompt)
        
        return {
            "agent": self.name,
            "task": task,
            "code": response.content,
            "summary": "ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸ",
            "status": "completed"
        }

class ReviewerAgent(BaseAgent):
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        super().__init__("Reviewer")
    
    def execute(self, context: Dict) -> Dict:
        task = context.get("task", "")
        shared_memory = context.get("shared_memory", {})
        
        # ã‚³ãƒ¼ãƒ€ãƒ¼ã®çµæœãŒã‚ã‚Œã°ãƒ¬ãƒ“ãƒ¥ãƒ¼
        code = shared_memory.get("coder", {}).get("code", "")
        
        prompt = f"""
        ä»¥ä¸‹ã®å†…å®¹ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¹ã‚¯: {task}
        
        ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡:
        {code if code else task}
        
        ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹:
        1. æ­£ç¢ºæ€§
        2. å®Œå…¨æ€§
        3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
        5. æ”¹å–„ææ¡ˆ
        """
        
        response = self.llm.invoke(prompt)
        
        return {
            "agent": self.name,
            "task": task,
            "review": response.content,
            "summary": "ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†",
            "status": "completed"
        }

class DocumenterAgent(BaseAgent):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        super().__init__("Documenter")
    
    def execute(self, context: Dict) -> Dict:
        task = context.get("task", "")
        shared_memory = context.get("shared_memory", {})
        
        # ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã‚’åé›†
        all_results = "\n".join([
            f"{agent}: {data.get('summary', '')}"
            for agent, data in shared_memory.items()
        ])
        
        prompt = f"""
        ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã¨çµæœã«ã¤ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¹ã‚¯: {task}
        
        å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœ:
        {all_results}
        
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å«ã‚ã‚‹å†…å®¹:
        1. æ¦‚è¦
        2. å®Ÿè£…è©³ç´°
        3. ä½¿ç”¨æ–¹æ³•
        4. æ³¨æ„ç‚¹
        5. å‚è€ƒæƒ…å ±
        """
        
        response = self.llm.invoke(prompt)
        
        return {
            "agent": self.name,
            "task": task,
            "documentation": response.content,
            "summary": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆå®Œäº†",
            "status": "completed"
        }
```

### 3. Streamlit UI

```python
# phase04-multi-agent/app.py

import streamlit as st
import asyncio
from src.supervisor import SupervisorAgent, AgentType
from src.specialized_agents import (
    ResearcherAgent,
    CoderAgent,
    ReviewerAgent,
    DocumenterAgent
)
from src.self_reflection import SelfReflectionAgent
from src.requirements_agent import RequirementsAgent
from src.plan_execute import PlanExecuteAgent

st.set_page_config(
    page_title="Multi-Agent System",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("""
è¤‡æ•°ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”èª¿ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("è¨­å®š")

agent_mode = st.sidebar.selectbox(
    "ãƒ¢ãƒ¼ãƒ‰é¸æŠ",
    [
        "ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",
        "ã‚»ãƒ«ãƒ•ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³",
        "è¦ä»¶å®šç¾©",
        "Plan-and-Execute"
    ]
)

execution_mode = st.sidebar.radio(
    "å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰",
    ["ä¸¦åˆ—", "é †æ¬¡"]
)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
if agent_mode == "ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ":
    st.header("ğŸ‘¥ ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰")
    
    task = st.text_area(
        "ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›",
        height=100,
        placeholder="ä¾‹: LangGraphã‚’ä½¿ã£ãŸRAGã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã¨å®Ÿè£…"
    )
    
    if st.button("å®Ÿè¡Œ", type="primary"):
        with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½œæ¥­ä¸­..."):
            # Supervisorã®åˆæœŸåŒ–
            supervisor = SupervisorAgent()
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç™»éŒ²
            supervisor.register_agent(AgentType.RESEARCHER, ResearcherAgent())
            supervisor.register_agent(AgentType.CODER, CoderAgent())
            supervisor.register_agent(AgentType.REVIEWER, ReviewerAgent())
            supervisor.register_agent(AgentType.DOCUMENTER, DocumenterAgent())
            
            # å®Ÿè¡Œ
            sequential = (execution_mode == "é †æ¬¡")
            result = asyncio.run(
                supervisor.coordinate_agents(task, sequential=sequential)
            )
            
            # çµæœè¡¨ç¤º
            st.success("å®Œäº†ï¼")
            
            # ä½¿ç”¨ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
            st.subheader("ğŸ¤– ä½¿ç”¨ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
            cols = st.columns(len(result["agents_used"]))
            for i, agent in enumerate(result["agents_used"]):
                with cols[i]:
                    st.metric(agent.title(), "âœ… å®Œäº†")
            
            # æœ€çµ‚çµæœ
            st.subheader("ğŸ“ æœ€çµ‚çµæœ")
            st.write(result["final_answer"])
            
            # å€‹åˆ¥çµæœ
            with st.expander("ğŸ” è©³ç´°çµæœ"):
                for agent, data in result["individual_results"].items():
                    st.subheader(f"{agent} ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
                    if isinstance(data, dict):
                        for key, value in data.items():
                            if key != "summary":
                                st.write(f"**{key}**: {value[:500]}...")
                    else:
                        st.write(data)

elif agent_mode == "ã‚»ãƒ«ãƒ•ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³":
    st.header("ğŸ¤” ã‚»ãƒ«ãƒ•ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰")
    
    task = st.text_area(
        "ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›",
        height=100
    )
    
    max_iterations = st.slider(
        "æœ€å¤§åå¾©å›æ•°",
        min_value=1,
        max_value=5,
        value=3
    )
    
    if st.button("å®Ÿè¡Œ", type="primary"):
        agent = SelfReflectionAgent(max_iterations=max_iterations)
        
        # åˆå›å¿œç­”ç”Ÿæˆé–¢æ•°
        def initial_generator(t):
            llm = ChatOpenAI(model="gpt-4o-mini")
            return llm.invoke(t).content
        
        with st.spinner("ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸­..."):
            result = agent.execute_with_reflection(
                task,
                initial_generator
            )
        
        st.success(f"å®Œäº†ï¼{result['iterations']}å›ã®åå¾©")
        
        # æœ€çµ‚çµæœ
        st.subheader("ğŸ¯ æœ€çµ‚çµæœ")
        st.write(result["final_response"])
        
        # ã‚¹ã‚³ã‚¢
        st.metric("æœ€çµ‚ã‚¹ã‚³ã‚¢", f"{result['final_score']:.1f}/10")
        
        # å±¥æ­´
        with st.expander("ğŸ“Š æ”¹å–„å±¥æ­´"):
            for item in result["history"]:
                st.write(f"**åå¾© {item['iteration'] + 1}**")
                st.write(f"ã‚¹ã‚³ã‚¢: {item['reflection']['quality_score']:.1f}")
                st.write(f"æ”¹å–„ç‚¹: {item['reflection']['improvements']}")

elif agent_mode == "è¦ä»¶å®šç¾©":
    st.header("ğŸ“„ è¦ä»¶å®šç¾©ãƒ¢ãƒ¼ãƒ‰")
    
    project = st.text_area(
        "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜",
        height=100,
        placeholder="ä¾‹: ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’AIã§æ¤œç´¢ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ "
    )
    
    if st.button("è¦ä»¶ç”Ÿæˆ", type="primary"):
        agent = RequirementsAgent()
        
        with st.spinner("ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆä¸­..."):
            personas = agent.generate_personas(project)
        
        st.subheader("ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒšãƒ«ã‚½ãƒŠ")
        
        for persona in personas:
            with st.expander(f"{persona.name} - {persona.role}"):
                st.write(f"**ç›®æ¨™**: {persona.goals}")
                st.write(f"**èª²é¡Œ**: {persona.pain_points}")
                st.write(f"**æœŸå¾…**: {persona.expectations}")
                
                # ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼
                if st.button(f"{persona.name}ã«ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", key=persona.name):
                    interview = agent.interview_persona(persona, project)
                    
                    st.write("ğŸ™ï¸ ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼çµæœ")
                    for qa in interview:
                        st.write(f"**Q: {qa['question']}**")
                        st.write(f"A: {qa['answer']}")
        
        # è¦ä»¶ç”Ÿæˆ
        if st.button("è¦ä»¶ã‚’ç”Ÿæˆ"):
            with st.spinner("è¦ä»¶ç”Ÿæˆä¸­..."):
                # ã™ã¹ã¦ã®ãƒšãƒ«ã‚½ãƒŠã«ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼
                all_interviews = []
                for p in personas:
                    interviews = agent.interview_persona(p, project)
                    all_interviews.extend(interviews)
                
                requirements = agent.generate_requirements(
                    project,
                    all_interviews
                )
            
            st.subheader("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸè¦ä»¶")
            
            for req in requirements:
                with st.expander(f"{req.category}: {req.description[:50]}..."):
                    st.write(f"**å„ªå…ˆåº¦**: {req.priority}")
                    st.write(f"**èª¬æ˜**: {req.description}")
                    st.write("**å—å…¥åŸºæº–**:")
                    for criteria in req.acceptance_criteria:
                        st.write(f"- {criteria}")

elif agent_mode == "Plan-and-Execute":
    st.header("ğŸ—ºï¸ Plan-and-Executeãƒ¢ãƒ¼ãƒ‰")
    
    objective = st.text_area(
        "ç›®æ¨™ã‚’å…¥åŠ›",
        height=100
    )
    
    if st.button("è¨ˆç”»ä½œæˆ", type="primary"):
        agent = PlanExecuteAgent()
        
        with st.spinner("è¨ˆç”»ä½œæˆä¸­..."):
            plan = agent.create_plan(objective)
        
        st.subheader("ğŸ“‹ å®Ÿè¡Œè¨ˆç”»")
        
        # è¨ˆç”»è¡¨ç¤º
        for step in plan:
            with st.expander(f"ã‚¹ãƒ†ãƒƒãƒ— {step.step_number}: {step.description[:50]}..."):
                st.write(f"**èª¬æ˜**: {step.description}")
                st.write(f"**æ¨å®šæ™‚é–“**: {step.estimated_time}")
                st.write(f"**ä¾å­˜**: {step.dependencies}")
                st.write(f"**ãƒ„ãƒ¼ãƒ«**: {step.required_tools}")
        
        # å®Ÿè¡Œ
        if st.button("è¨ˆç”»ã‚’å®Ÿè¡Œ"):
            with st.spinner("å®Ÿè¡Œä¸­..."):
                execution_log = agent.execute_plan(plan)
            
            st.subheader("âœ… å®Ÿè¡Œçµæœ")
            
            for log in execution_log:
                if log["status"] == "completed":
                    st.success(f"ã‚¹ãƒ†ãƒƒãƒ— {log['step_number']}: å®Œäº†")
                    with st.expander("è©³ç´°"):
                        st.write(log["result"])
                else:
                    st.warning(f"ã‚¹ãƒ†ãƒƒãƒ— {log['step_number']}: {log['status']}")

if __name__ == "__main__":
    st.sidebar.markdown("---")
    st.sidebar.info(
        """
        **Phase 4 ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ **
        
        è¤‡æ•°ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”èª¿ã—ã¦
        è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã—ã¾ã™ã€‚
        """
    )
```

---

## ğŸš€ å®Ÿè¡Œæ‰‹é †

```bash
# ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
cd phase04-multi-agent
python -m venv .venv
source .venv/bin/activate

# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
pip install -r requirements.txt

# Streamlitã‚¢ãƒ—ãƒªèµ·å‹•
streamlit run app.py
```

---

## ğŸ¯ æˆåŠŸåŸºæº–

### Day 3
- [ ] ã‚»ãƒ«ãƒ•ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Œå‹•
- [ ] è¦ä»¶å®šç¾©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
- [ ] Plan-and-Executeå®Ÿè£…

### Day 4
- [ ] Supervisorã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œæˆ
- [ ] 4ç¨®é¡ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
- [ ] Streamlit UIçµ±åˆ
- [ ] å…¨æ©Ÿèƒ½ãƒ‡ãƒ¢æˆåŠŸ

---

*æœ€çµ‚æ›´æ–°: 2025å¹´1æœˆ21æ—¥*