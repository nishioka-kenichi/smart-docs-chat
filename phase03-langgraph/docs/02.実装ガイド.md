# Phase 3 LangGraphエージェント - 実装ガイド

## 📌 概要

Phase 3では、LangGraphを使用して自律的に動作するAIエージェントを実装しています。
本ガイドでは、実装の詳細と使用方法を説明します。

---

## 🚀 クイックスタート

### 1. 環境セットアップ

```bash
# Phase 3ディレクトリに移動
cd phase03-langgraph

# Python仮想環境の作成と有効化
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 依存パッケージのインストール
pip install -r requirements.txt
```

### 2. 環境変数の設定

```bash
# .envファイルを作成
cp .env.example .env

# .envファイルを編集して必要な情報を設定
# 必須:
#   - OPENAI_API_KEY
# オプション:
#   - TAVILY_API_KEY (Web検索を使用する場合)
#   - CHROMADB_PATH (デフォルト: ../phase01-local/data/chromadb)
```

### 3. 基本的な実行

```bash
# 対話モードで起動
python src/main.py

# 単一のクエリを実行
python src/main.py "社内の就業規則について教えてください"

# 詳細ログを非表示にする
python src/main.py --quiet "質問内容"

# グラフの可視化
python src/main.py --visualize
```

---

## 💻 使用方法

### 対話モード

対話モードでは、継続的に質問を入力できます：

```bash
$ python src/main.py --interactive

🤖 LangGraph Agent - Interactive Mode
============================================================
Commands:
  /exit    - 終了
  /clear   - 会話履歴をクリア
  /save    - チェックポイントを保存
  /load    - チェックポイントから復元
  /list    - チェックポイント一覧
  /tools   - 利用可能なツール一覧
  /help    - ヘルプを表示
============================================================

🧑 You: Notionにある営業資料について教えて

🤖 Agent: Thinking...

[推論プロセスが表示されます]

🤖 Agent: 営業資料について以下の情報が見つかりました...
```

### コマンドライン引数

```bash
# ヘルプを表示
python src/main.py --help

# オプション:
#   query               処理するクエリ（省略時は対話モード）
#   --interactive, -i   対話モードで実行
#   --resume ID         チェックポイントIDから再開
#   --config PATH       設定ファイルのパス
#   --quiet, -q         詳細ログを非表示
#   --visualize, -v     エージェントグラフを可視化
```

---

## 🔧 設定のカスタマイズ

### config/settings.yaml

主要な設定項目：

```yaml
# エージェント設定
agent:
  max_iterations: 10          # 最大推論ループ数
  timeout_seconds: 60         # タイムアウト時間
  verbose: true              # 詳細ログ出力

# LLM設定
llm:
  model: "gpt-4o-mini"       # 使用するモデル
  temperature: 0.7           # 生成の多様性
  max_tokens: 2000          # 最大トークン数

# ツール設定
tools:
  rag_search:
    enabled: true            # RAG検索を有効化
    top_k: 5                # 検索結果数
  web_search:
    enabled: false          # Web検索（要APIキー）
  calculator:
    enabled: true           # 計算ツール
  file_handler:
    enabled: true           # ファイル操作
```

---

## 🛠️ ツールの使用

### 利用可能なツール

1. **RAG検索** (`rag_search`)
   - Phase 1のChromaDBを使用
   - 社内ドキュメントの検索

2. **計算機** (`calculator`)
   - 数式の評価
   - 基本的な数学関数

3. **ファイル操作** (`read_file`, `write_file`)
   - テキストファイルの読み書き
   - 対応形式: .txt, .md, .json, .csv

4. **Web検索** (`web_search`) ※オプション
   - Tavily APIを使用
   - 最新情報の取得

### ツールの追加方法

新しいツールを追加する場合：

```python
# src/tools.pyに追加

def _setup_custom_tool(self):
    """カスタムツールのセットアップ"""
    tool = StructuredTool.from_function(
        func=self._custom_function,
        name="custom_tool",
        description="ツールの説明",
        args_schema=CustomToolInput
    )
    self.tools.append(tool)

def _custom_function(self, param: str) -> str:
    """カスタム機能の実装"""
    # 処理を実装
    return "結果"
```

---

## 🔍 デバッグとトラブルシューティング

### 詳細ログの有効化

```python
# コード内で設定
agent = ReActAgent(verbose=True)

# または環境変数で設定
export LANGGRAPH_LOG_LEVEL=DEBUG
```

### よくある問題と解決方法

#### 1. ChromaDBへの接続エラー

```bash
# Phase 1のデータベースパスを確認
export CHROMADB_PATH="../phase01-local/data/chromadb"

# Phase 1でインデックスを再構築
cd ../phase01-local
python src/indexer.py
```

#### 2. OpenAI APIエラー

```bash
# APIキーの確認
echo $OPENAI_API_KEY

# レート制限の場合は待機
# または.envでモデルを変更
OPENAI_MODEL=gpt-3.5-turbo
```

#### 3. メモリ不足

```yaml
# config/settings.yamlで調整
agent:
  max_iterations: 5  # イテレーション数を減らす
llm:
  max_tokens: 1000   # トークン数を減らす
```

---

## 🧪 テストの実行

```bash
# 全テストを実行
pytest tests/

# 特定のテストファイルを実行
pytest tests/test_agent.py -v

# カバレッジレポート付き
pytest tests/ --cov=src --cov-report=html
```

### テストファイル構成

- `test_agent.py`: エージェントとState管理のテスト
- `test_tools.py`: 各ツールの単体テスト  
- `test_graph.py`: グラフ構築と実行のテスト

---

## 📊 パフォーマンスチューニング

### 応答速度の改善

```yaml
# config/settings.yaml
llm:
  streaming: true           # ストリーミング有効化
  model: "gpt-3.5-turbo"   # 軽量モデル使用

graph:
  enable_parallel: true     # 並列処理有効化
  enable_caching: true      # キャッシュ有効化
```

### メモリ使用量の削減

```yaml
checkpoint:
  compression: true         # 圧縮保存
  max_checkpoints: 5       # 保存数制限
  auto_save: false         # 自動保存無効化
```

---

## 🔄 チェックポイント機能

### チェックポイントの管理

```python
# プログラム内での使用
from checkpointer import CheckpointManager

manager = CheckpointManager()

# 保存
checkpoint_id = manager.save_checkpoint(
    state=current_state,
    step_name="reasoning",
    iteration=3
)

# 読み込み
checkpoint = manager.load_checkpoint(checkpoint_id)

# 一覧取得
checkpoints = manager.list_checkpoints()
```

### 対話モードでの使用

```bash
# チェックポイント一覧を表示
/list

# 最新のチェックポイントから再開
/load

# 現在の状態を保存
/save
```

---

## 📈 メトリクスとモニタリング

### 実行統計の確認

実行後に以下の情報が表示されます：

- **Reasoning steps**: 推論ステップ数
- **Tool calls**: ツール呼び出し回数
- **Iterations**: 総イテレーション数
- **Response time**: 応答時間

### ログファイルの確認

```bash
# ログファイルの場所
tail -f data/logs/agent.log

# ログレベルの変更
export LANGGRAPH_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
```

---

## 🚀 プロダクション環境への展開

### 推奨設定

```yaml
# config/settings.yaml (本番環境用)
agent:
  max_iterations: 10
  timeout_seconds: 30
  verbose: false

llm:
  model: "gpt-4o-mini"
  temperature: 0.3  # より確定的な応答

checkpoint:
  enabled: true
  compression: true
  max_checkpoints: 20

logging:
  level: "WARNING"
  rotate_size: "100MB"
```

### セキュリティ考慮事項

1. **APIキーの管理**
   - 環境変数で管理
   - シークレット管理サービスの使用

2. **入力のサニタイズ**
   ```yaml
   security:
     sanitize_inputs: true
     max_input_length: 5000
   ```

3. **レート制限**
   ```yaml
   security:
     rate_limit: 60  # リクエスト/分
   ```

---

## 📚 参考リンク

- [LangGraph公式ドキュメント](https://github.com/langchain-ai/langgraph)
- [ReActパターン論文](https://arxiv.org/abs/2210.03629)
- [Phase 1 README](../phase01-local/README.md)
- [Phase 2 README](../phase02-advanced-rag/README.md)

---

*最終更新: 2025年1月22日*