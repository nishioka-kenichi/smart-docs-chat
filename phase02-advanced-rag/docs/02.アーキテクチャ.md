# Phase 2: Advanced RAG アーキテクチャ設計

## 🏗️ システム全体図

```mermaid
graph TB
    subgraph "入力層"
        User[ユーザー]
        Query[質問]
    end
    
    subgraph "Advanced RAG層"
        subgraph "検索拡張"
            HyDE[HyDE<br/>仮想回答生成]
            Fusion[RAG-Fusion<br/>複数クエリ生成]
        end
        
        subgraph "検索層"
            VectorDB[(ChromaDB<br/>Phase 1参照)]
            Search[類似検索]
        end
        
        subgraph "後処理層"
            Merger[結果統合]
            Reranker[Reranker<br/>再順位付け]
        end
    end
    
    subgraph "生成層"
        Context[コンテキスト構築]
        LLM[GPT-4o-mini]
        Answer[回答生成]
    end
    
    User --> Query
    Query --> HyDE
    Query --> Fusion
    
    HyDE --> Search
    Fusion --> Search
    Search --> VectorDB
    VectorDB --> Merger
    
    Merger --> Reranker
    Reranker --> Context
    Context --> LLM
    LLM --> Answer
    Answer --> User
    
    style User fill:#FFE4B5
    style Answer fill:#90EE90
    style VectorDB fill:#87CEEB
```

---

## 📐 コンポーネント設計

### 1. HyDEコンポーネント

```mermaid
classDiagram
    class HyDE {
        -llm: ChatOpenAI
        -embeddings: OpenAIEmbeddings
        -vectorstore: Chroma
        -hyde_prompt: PromptTemplate
        +generate_hypothetical_documents(query, num)
        +search_with_hyde(query, k)
    }
```

**責務**:
- 質問から仮想回答を生成
- 仮想回答による検索実行
- 結果の重複除去

### 2. RAG-Fusionコンポーネント

```mermaid
classDiagram
    class RAGFusion {
        -llm: ChatOpenAI
        -vectorstore: Chroma
        -query_prompt: PromptTemplate
        +generate_queries(query, num)
        +reciprocal_rank_fusion(results, k)
        +search_with_fusion(query, k)
    }
```

**責務**:
- 複数の検索クエリ生成
- 並列検索の実行
- RRFによる結果統合

### 3. Rerankerコンポーネント

```mermaid
classDiagram
    class BaseReranker {
        <<abstract>>
        +rerank(query, docs, k)
    }
    
    class CohereReranker {
        -client: cohere.Client
        +rerank(query, docs, k)
    }
    
    class CrossEncoderReranker {
        -model: CrossEncoder
        +rerank(query, docs, k)
    }
    
    class HybridReranker {
        -rerankers: List[BaseReranker]
        +rerank(query, docs, k)
    }
    
    BaseReranker <|-- CohereReranker
    BaseReranker <|-- CrossEncoderReranker
    BaseReranker <|-- HybridReranker
```

**責務**:
- 検索結果の再評価
- スコアベースの再順位付け
- 複数手法のハイブリッド実行

---

## 🔄 データフロー

### 1. 検索フロー

```mermaid
sequenceDiagram
    participant U as ユーザー
    participant C as Controller
    participant H as HyDE
    participant F as RAG-Fusion
    participant V as VectorDB
    participant R as Reranker
    
    U->>C: 質問入力
    
    par 並列処理
        C->>H: HyDE検索依頼
        H->>H: 仮想回答生成
        H->>V: 仮想回答で検索
        V-->>H: 検索結果A
    and
        C->>F: Fusion検索依頼
        F->>F: 複数クエリ生成
        F->>V: 並列検索
        V-->>F: 検索結果B
    end
    
    H-->>C: 結果A返却
    F-->>C: 結果B返却
    
    C->>C: 結果統合
    C->>R: 再順位付け依頼
    R-->>C: 最終結果
    C-->>U: 上位K件返却
```

### 2. 回答生成フロー

```mermaid
sequenceDiagram
    participant C as Controller
    participant D as Documents
    participant P as Prompt Builder
    participant L as LLM
    participant U as ユーザー
    
    C->>D: 上位文書取得
    D->>P: コンテキスト構築
    P->>P: プロンプト生成
    P->>L: 生成依頼
    L->>L: 回答生成
    L-->>C: 生成結果
    C-->>U: 最終回答
```

---

## 💾 データモデル

### SearchResult
```python
@dataclass
class SearchResult:
    document: Document
    score: float
    method: str  # "hyde", "fusion", "base"
    metadata: Dict[str, Any]
```

### AdvancedRAGResponse
```python
@dataclass
class AdvancedRAGResponse:
    query: str
    answer: str
    source_documents: List[Document]
    scores: List[float]
    retrieval_time: float
    generation_time: float
    total_time: float
    config_used: Dict[str, bool]
```

---

## ⚙️ 設定管理

### 設定ファイル構造

```yaml
# config/settings.yaml

# ChromaDB設定（Phase 1を参照）
chromadb:
  persist_directory: "../phase01-local/data/chromadb"
  collection_name: "phase01_documents"

# HyDE設定
hyde:
  enabled: true
  num_hypothetical: 3
  temperature: 0.7
  max_length: 500

# RAG-Fusion設定
fusion:
  enabled: true
  num_queries: 5
  rrf_k: 60

# Reranker設定
reranker:
  enabled: true
  type: "hybrid"  # "cohere", "cross_encoder", "hybrid"
  top_k: 10
  
# LLM設定
llm:
  model: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 1000

# パフォーマンス設定
performance:
  cache_enabled: true
  cache_ttl: 3600
  batch_size: 10
  max_workers: 4
```

---

## 🔐 エラーハンドリング

### フォールバック戦略

```mermaid
graph TD
    A[処理開始] --> B{HyDE成功?}
    B -->|Yes| C[HyDE結果使用]
    B -->|No| D[通常検索へ]
    
    C --> E{Fusion成功?}
    D --> E
    
    E -->|Yes| F[Fusion結果追加]
    E -->|No| G[単一検索結果]
    
    F --> H{Reranker成功?}
    G --> H
    
    H -->|Yes| I[再順位付け結果]
    H -->|No| J[元の順位維持]
    
    I --> K[最終結果]
    J --> K
```

### エラー種別と対処

| エラー種別 | 原因 | 対処法 |
|-----------|------|--------|
| API Timeout | ネットワーク遅延 | リトライ（指数バックオフ） |
| Rate Limit | API制限超過 | 待機後リトライ or フォールバック |
| Memory Error | モデルサイズ大 | バッチサイズ削減 |
| Invalid Response | LLM出力エラー | プロンプト調整 or 再実行 |

---

## 📊 モニタリング

### 監視メトリクス

1. **パフォーマンス**
   - 各コンポーネントの処理時間
   - エンドツーエンドのレイテンシ
   - スループット（req/sec）

2. **品質**
   - 検索精度（Precision/Recall）
   - 回答の関連性スコア
   - ユーザーフィードバック

3. **リソース**
   - メモリ使用量
   - API呼び出し回数
   - キャッシュヒット率

### ログ設計

```python
# ログレベル
DEBUG: 詳細な処理フロー
INFO: 主要な処理ステップ
WARNING: フォールバック発生
ERROR: エラー発生
```

---

## 🚀 スケーラビリティ

### 水平スケーリング
- 検索処理の並列化
- 複数インスタンスでの負荷分散

### 垂直スケーリング
- GPUによるモデル推論高速化
- メモリ増設による大規模バッチ処理

### キャッシング戦略
- クエリ結果のキャッシュ（TTL: 1時間）
- 埋め込みベクトルのキャッシュ
- LLM応答のキャッシュ（同一質問）

---

*最終更新: 2025年1月21日*